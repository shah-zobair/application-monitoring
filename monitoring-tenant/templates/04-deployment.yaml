---
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus
  labels:
    prometheus: k8s
  namespace: {{ .Values.monitoring_namespace }}
spec:
  replicas: 2
  serviceAccountName: monitoring
  securityContext: {}
  serviceMonitorNamespaceSelector: {}
  serviceMonitorSelector:
    matchExpressions:
      - key: k8s-app
        operator: Exists
  ruleSelector:
    matchLabels:
      role: prometheus-rulefiles
      prometheus: k8s
  alerting:
    alertmanagers:
      - namespace: {{ .Values.monitoring_namespace }}
        name: alertmanager-main
        port: web
---
apiVersion: integreatly.org/v1alpha1
kind: GrafanaDataSource
metadata:
  name: grafana-datasource
  namespace: {{ .Values.monitoring_namespace }}
spec:
  datasources:
    - access: proxy
      editable: true
      isDefault: true
      jsonData:
        timeInterval: 5s
      name: Prometheus
      type: prometheus
      url: 'http://prometheus-operated:9090'
      version: 1
  name: grafana-datasources.yaml
---
apiVersion: integreatly.org/v1alpha1
kind: Grafana
metadata:
  name: grafana
  namespace: {{ .Values.monitoring_namespace }}
spec:
  client:
    preferService: true
  ingress:
    enabled: false
  config:
    auth:
      disable_signout_menu: true
    auth.anonymous:
      enabled: true
    log:
      level: debug
      mode: console
  service:
    name: "grafana-service"
    labels:
      app: "grafana"
      type: "grafana-service"
  dashboardLabelSelector:
    - matchExpressions:
        - { key: app, operator: In, values: [ grafana ] }
---
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: monitoring
spec:
  replicas: 3
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/version: v1.9.7
    monitoring: "true"
  name: kube-state-metrics
  namespace: {{ .Values.monitoring_namespace }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/version: v1.9.7
        monitoring: "true"
    spec:
      containers:
      - args:
        - --host=127.0.0.1
        - --port=8081
        - --telemetry-host=127.0.0.1
        - --telemetry-port=8082
        - --namespace={{ join "," .Values.workload_namespace }}
        image: quay.io/coreos/kube-state-metrics:v1.9.7
        name: kube-state-metrics
      - args:
        - --logtostderr
        - --secure-listen-address=:8443
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --upstream=http://127.0.0.1:8081/
        #image: quay.io/brancz/kube-rbac-proxy:v0.8.0
        image: registry.redhat.io/openshift4/ose-kube-rbac-proxy:v4.7.0
        name: kube-rbac-proxy-main
        ports:
        - containerPort: 8443
          name: https-main
        securityContext:
          #runAsGroup: 65532
          runAsNonRoot: true
          #runAsUser: 65532
      - args:
        - --logtostderr
        - --secure-listen-address=:9443
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --upstream=http://127.0.0.1:8082/
        #image: quay.io/brancz/kube-rbac-proxy:v0.8.0
        image: registry.redhat.io/openshift4/ose-kube-rbac-proxy:v4.7.0
        name: kube-rbac-proxy-self
        ports:
        - containerPort: 9443
          name: https-self
        securityContext:
          #runAsGroup: 65532
          runAsNonRoot: true
          #runAsUser: 65532
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: kube-state-metrics
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prometheus-example-app
    monitoring: "true"
  name: prometheus-example-app
  namespace: {{ .Values.monitoring_namespace }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus-example-app
  template:
    metadata:
      labels:
        app: prometheus-example-app
        monitoring: "true"
    spec:
      containers:
      - image: quay.io/brancz/prometheus-example-app:v0.2.0
        imagePullPolicy: IfNotPresent
        name: prometheus-example-app
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
  labels:
    app: sample-monitoring-app
    monitoring: "true"
  name: sample-monitoring-app
  namespace: {{ .Values.monitoring_namespace }}
spec:
  progressDeadlineSeconds: 600
  revisionHistoryLimit: 10
  replicas: 1
  selector:
    matchLabels:
      app: sample-monitoring-app
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
      creationTimestamp: null
      labels:
        app: sample-monitoring-app
        monitoring: "true"
    spec:
      containers:
      - args:
        - -c
        - |
          /run.sh
        command:
        - /bin/bash
        image: quay.io/szobair/sample-monitoring-app
        imagePullPolicy: IfNotPresent
        name: sample-monitoring-app
        resources: {}
        securityContext: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        ports:
        - containerPort: 8080
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      securityContext: {}
      terminationGracePeriodSeconds: 30
---
